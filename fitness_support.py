# -*- coding: utf-8 -*-
"""fitness support.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YQXw1m41JJRzbXC0GIDGKDwUlxVAHoBq
"""

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score

# Load the dataset
file_path = '/content/BodyFat - Extended.csv'
data = pd.read_csv(file_path)

# Preprocessing: Encode categorical variables ('Sex') and drop unnecessary columns
data['Sex'] = data['Sex'].map({'M': 1, 'F': 0})  # Map 'M' to 1 and 'F' to 0
data = data.drop(columns=['Original'])

# Features (X) and target (y)
X = data.drop(columns=['BodyFat'])
y = data['BodyFat']

# Split the dataset into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 1: Use a RandomForestRegressor
model_rf = RandomForestRegressor(random_state=42)

# Define a hyperparameter grid for tuning
param_grid = {
    'n_estimators': [100, 200, 500],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

# Use GridSearchCV for hyperparameter tuning
grid_search = GridSearchCV(estimator=model_rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)
grid_search.fit(X_train_scaled, y_train)

# The best model from grid search
best_rf_model = grid_search.best_estimator_

# Step 2: Evaluate the model
y_pred = best_rf_model.predict(X_test_scaled)

# Calculate metrics
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mse:.2f}")
print(f"R² Score: {r2:.2f}")

import seaborn as sns
import matplotlib.pyplot as plt

# Correlation heatmap
corr_matrix = data.corr()
plt.figure(figsize=(12,8))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')
plt.title('Correlation Heatmap of Features')
plt.show()

# Feature importance from the trained RandomForest model
importances = best_rf_model.feature_importances_
feature_names = X.columns

# Create a sorted feature importance plot
sorted_indices = importances.argsort()[::-1]
plt.figure(figsize=(10,6))
plt.barh(range(len(sorted_indices)), importances[sorted_indices], align='center')
plt.yticks(range(len(sorted_indices)), [feature_names[i] for i in sorted_indices])
plt.title("Feature Importance (Random Forest)")
plt.xlabel('Importance')
plt.show()

from sklearn.model_selection import cross_val_score

# Perform cross-validation and evaluate with R² score
cross_val_scores = cross_val_score(best_rf_model, X_train_scaled, y_train, cv=5, scoring='r2')
print(f"Cross-Validation R² Scores: {cross_val_scores}")
print(f"Mean Cross-Validation R²: {cross_val_scores.mean():.2f}")

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score

# Load the dataset
file_path = '/content/BodyFat - Extended.csv'
data = pd.read_csv(file_path)

# Preprocessing: Encode categorical variables ('Sex') and drop unnecessary columns
data['Sex'] = data['Sex'].map({'M': 1, 'F': 0})  # Map 'M' to 1 and 'F' to 0
data = data.drop(columns=['Original'])

# Features (X) and target (y)
X = data.drop(columns=['BodyFat'])
y = data['BodyFat']

# Split the dataset into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 1: Use a RandomForestRegressor and tune it
model_rf = RandomForestRegressor(random_state=42)

# Define a hyperparameter grid for tuning
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

# Use GridSearchCV for hyperparameter tuning
grid_search = GridSearchCV(estimator=model_rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)
grid_search.fit(X_train_scaled, y_train)

# The best model from grid search
best_rf_model = grid_search.best_estimator_

# Step 2: Define a function to take user input and make predictions
def predict_body_fat():
    # Prompt the user for input
    age = int(input("Enter Age: "))
    sex = input("Enter Sex (M/F): ").strip().upper()
    sex = 1 if sex == 'M' else 0  # Convert to 1 for Male, 0 for Female
    weight = float(input("Enter Weight (in kg): "))
    height = float(input("Enter Height (in meters): "))
    neck = float(input("Enter Neck Circumference (in cm): "))
    chest = float(input("Enter Chest Circumference (in cm): "))
    abdomen = float(input("Enter Abdomen Circumference (in cm): "))
    hip = float(input("Enter Hip Circumference (in cm): "))
    thigh = float(input("Enter Thigh Circumference (in cm): "))
    knee = float(input("Enter Knee Circumference (in cm): "))
    ankle = float(input("Enter Ankle Circumference (in cm): "))
    biceps = float(input("Enter Biceps Circumference (in cm): "))
    forearm = float(input("Enter Forearm Circumference (in cm): "))
    wrist = float(input("Enter Wrist Circumference (in cm): "))

    # Create a DataFrame for the new input
    user_data = pd.DataFrame({
        'Age': [age],
        'Sex': [sex],  # 1 for Male, 0 for Female
        'Weight': [weight],
        'Height': [height],
        'Neck': [neck],
        'Chest': [chest],
        'Abdomen': [abdomen],
        'Hip': [hip],
        'Thigh': [thigh],
        'Knee': [knee],
        'Ankle': [ankle],
        'Biceps': [biceps],
        'Forearm': [forearm],
        'Wrist': [wrist]
    })

    # Scale the user input using the same scaler
    user_data_scaled = scaler.transform(user_data)

    # Make a prediction using the trained RandomForest model
    prediction = best_rf_model.predict(user_data_scaled)
    return prediction[0]

# Call the function and display the result
predicted_body_fat = predict_body_fat()
print(f"Predicted Body Fat Percentage: {predicted_body_fat:.2f}%")

# Import necessary libraries
import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score

# Load the dataset
file_path = '/content/BodyFat - Extended.csv'
data = pd.read_csv(file_path)

# Preprocessing: Encode categorical variables ('Sex') and drop unnecessary columns
data['Sex'] = data['Sex'].map({'M': 1, 'F': 0})  # Map 'M' to 1 and 'F' to 0
data = data.drop(columns=['Original'])

# Features (X) and target (y)
X = data.drop(columns=['BodyFat'])
y = data['BodyFat']

# Split the dataset into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Step 1: Use a RandomForestRegressor and tune it
model_rf = RandomForestRegressor(random_state=42)

# Define a hyperparameter grid for tuning
param_grid = {
    'n_estimators': [100, 200],
    'max_depth': [None, 10, 20],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

# Use GridSearchCV for hyperparameter tuning
grid_search = GridSearchCV(estimator=model_rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)
grid_search.fit(X_train_scaled, y_train)

# The best model from grid search
best_rf_model = grid_search.best_estimator_

# Step 2: Define a function to take user input and make predictions
def predict_body_fat():
    # Prompt the user for input
    age = int(input("Enter Age: "))
    sex = input("Enter Sex (M/F): ").strip().upper()
    sex = 1 if sex == 'M' else 0  # Convert to 1 for Male, 0 for Female
    weight = float(input("Enter Weight (in kg): "))
    height = float(input("Enter Height (in meters): "))
    neck = float(input("Enter Neck Circumference (in cm): "))
    chest = float(input("Enter Chest Circumference (in cm): "))
    abdomen = float(input("Enter Abdomen Circumference (in cm): "))
    hip = float(input("Enter Hip Circumference (in cm): "))
    thigh = float(input("Enter Thigh Circumference (in cm): "))
    knee = float(input("Enter Knee Circumference (in cm): "))
    ankle = float(input("Enter Ankle Circumference (in cm): "))
    biceps = float(input("Enter Biceps Circumference (in cm): "))
    forearm = float(input("Enter Forearm Circumference (in cm): "))
    wrist = float(input("Enter Wrist Circumference (in cm): "))

    # Create a DataFrame for the new input using the same column order as in X_train
    user_data = pd.DataFrame({
        'Age': [age],
        'Sex': [sex],  # 1 for Male, 0 for Female
        'Weight': [weight],
        'Height': [height],
        'Neck': [neck],
        'Chest': [chest],
        'Abdomen': [abdomen],
        'Hip': [hip],
        'Thigh': [thigh],
        'Knee': [knee],
        'Ankle': [ankle],
        'Biceps': [biceps],
        'Forearm': [forearm],
        'Wrist': [wrist]
    })

    # Ensure the columns are in the correct order based on the training data
    user_data = user_data[X_train.columns]

    # Scale the user input using the same scaler
    user_data_scaled = scaler.transform(user_data)

    # Make a prediction using the trained RandomForest model
    prediction = best_rf_model.predict(user_data_scaled)
    return prediction[0]

# Call the function and display the result
predicted_body_fat = predict_body_fat()
print(f"Predicted Body Fat Percentage: {predicted_body_fat:.2f}%")

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

# Make predictions on the test set
y_pred = best_rf_model.predict(X_test_scaled)

# Calculate MSE
mse = mean_squared_error(y_test, y_pred)

# Calculate RMSE
rmse = np.sqrt(mse)

# Calculate MAE
mae = mean_absolute_error(y_test, y_pred)

# Calculate R² score
r2 = r2_score(y_test, y_pred)

# Print the results
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"R² Score: {r2:.2f}")

# Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import xgboost as xgb

# Load the dataset
file_path = '/content/BodyFat - Extended.csv'
data = pd.read_csv(file_path)

# Feature Engineering: Create new features (e.g., BMI, body part ratios)
data['BMI'] = data['Weight'] / (data['Height'] ** 2)  # Calculate BMI
data['Abdomen_Height_Ratio'] = data['Abdomen'] / data['Height']  # Abdomen to height ratio
data['Hip_Height_Ratio'] = data['Hip'] / data['Height']  # Hip to height ratio

# Preprocessing: Encode categorical variables ('Sex') and drop unnecessary columns
data['Sex'] = data['Sex'].map({'M': 1, 'F': 0})  # Map 'M' to 1 and 'F' to 0
data = data.drop(columns=['Original'])  # Remove any unnecessary columns

# Define Features (X) and Target (y)
X = data.drop(columns=['BodyFat'])
y = data['BodyFat']

# Split the dataset into training and testing sets (80% training, 20% testing)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Initialize the XGBoost Regressor
model_xgb = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)

# Define hyperparameter grid for tuning
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}

# Use GridSearchCV for hyperparameter tuning
grid_search = GridSearchCV(estimator=model_xgb, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, scoring='neg_mean_squared_error')
grid_search.fit(X_train_scaled, y_train)

# The best model from grid search
best_xgb_model = grid_search.best_estimator_

# Evaluate the performance on the test set
y_pred = best_xgb_model.predict(X_test_scaled)

# Calculate performance metrics
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Print the results
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f}")
print(f"Mean Absolute Error (MAE): {mae:.2f}")
print(f"R² Score: {r2:.2f}")

# Step 2: Define a function to take user input and make predictions
def predict_body_fat():
    # Prompt the user for input
    age = int(input("Enter Age: "))
    sex = input("Enter Sex (M/F): ").strip().upper()
    sex = 1 if sex == 'M' else 0  # Convert to 1 for Male, 0 for Female
    weight = float(input("Enter Weight (in kg): "))
    height = float(input("Enter Height (in meters): "))
    neck = float(input("Enter Neck Circumference (in cm): "))
    chest = float(input("Enter Chest Circumference (in cm): "))
    abdomen = float(input("Enter Abdomen Circumference (in cm): "))
    hip = float(input("Enter Hip Circumference (in cm): "))
    thigh = float(input("Enter Thigh Circumference (in cm): "))
    knee = float(input("Enter Knee Circumference (in cm): "))
    ankle = float(input("Enter Ankle Circumference (in cm): "))
    biceps = float(input("Enter Biceps Circumference (in cm): "))
    forearm = float(input("Enter Forearm Circumference (in cm): "))
    wrist = float(input("Enter Wrist Circumference (in cm): "))

    # Create additional features (BMI, ratios)
    bmi = weight / (height ** 2)
    abdomen_height_ratio = abdomen / height
    hip_height_ratio = hip / height

    # Create a DataFrame for the new input using the same column order as in X_train
    user_data = pd.DataFrame({
        'Age': [age],
        'Sex': [sex],  # 1 for Male, 0 for Female
        'Weight': [weight],
        'Height': [height],
        'Neck': [neck],
        'Chest': [chest],
        'Abdomen': [abdomen],
        'Hip': [hip],
        'Thigh': [thigh],
        'Knee': [knee],
        'Ankle': [ankle],
        'Biceps': [biceps],
        'Forearm': [forearm],
        'Wrist': [wrist],
        'BMI': [bmi],  # New feature
        'Abdomen_Height_Ratio': [abdomen_height_ratio],  # New feature
        'Hip_Height_Ratio': [hip_height_ratio]  # New feature
    })

    # Ensure the columns are in the correct order based on the training data
    user_data = user_data[X_train.columns]

    # Scale the user input using the same scaler
    user_data_scaled = scaler.transform(user_data)

    # Make a prediction using the trained XGBoost model
    prediction = best_xgb_model.predict(user_data_scaled)
    return prediction[0]

# Call the function and display the result
predicted_body_fat = predict_body_fat()
print(f"Predicted Body Fat Percentage: {predicted_body_fat:.2f}%")